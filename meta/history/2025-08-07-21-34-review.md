# Zhenren Requirements Review — Functional, UX, Technical, Operational

Principles applied: Simplicity >> elegance >> normality >> robustness >> performance >> functionality. Findings prioritize simpler, clearer choices first; add complexity only where value is clear.

## Functional
- Completeness: Core flows (LLM chat, Documents create/read/list, semantic search) are coherent and minimal. Update/delete intentionally deferred — OK for v1.
- Search: Results omit snippets. Consider optional snippet/preview (client-side fetch of top N docs to render excerpts) only if users struggle to choose; default to titles-only to keep simple.
- Validation: Title/content length limits defined in API; ensure client mirrors them and prevents overflows before requests.
- Draft Handling: Document create preserves drafts on failure — good. Add explicit auto-draft for long content at a fixed cadence with clear discard controls.
- Query Limits: Search `limit` clamped at 20; consider a fixed UI default (e.g., 10) with no user control initially to reduce complexity.
- Error Contract: Strong requirement to surface original messages; ensure a consistent JSON shape in API and parsing in client to avoid special-casing.
- Internationalization: Marked “ready”; OK to defer actual locales. Ensure no hard-coded date/number formats in early UI.
- Accessibility: Declared; ensure focus handling for drawers/sheets and keyboard navigation for menu/Config.

## UX
- IA: Two-section structure (Home, Documents) + global Config is simple and teachable. Keep it.
- Error Surfacing: Inline, contextual, original messages with summaries — excellent. Add subtle color coding (warning/error) while keeping text primary.
- Offline: Global banner + per-action disablement is good. Add queued retry for only the last failed action on explicit user request; avoid auto retry.
- Prompt Editing: CodeMirror on web, multiline TextInput on native — pragmatic. Offer a preview for Markdown if it helps clarity, behind a toggle.
- Stale Labels: “Stale” for cached lists/models is good; include a last-updated timestamp to ground user trust.
- Loading: Show skeletons/spinners for list/search; stream/chat indicators for LLM. Respect reduced motion.
- Discoverability: When LLM disabled (missing config), provide a one-tap shortcut to open Config.
- Safety: Confirm navigation away from unsaved document drafts; retain across reloads.

## Technical
- Client Stack: Expo + Tamagui + TanStack Query + zod + CodeMirror is sensible and mainstream. Avoid Redux/extra state libs for now (simplicity).
- LLM Calls: Direct to OpenRouter from client minimizes backend complexity but exposes IP/User-Agent; acceptable for prototyping. If abuse or CORS arises, add a minimal proxy later.
- Token/Context Limits: Callers may hit provider token limits with long prompts. Add a soft client-side warning once prompt length exceeds a configurable threshold; do not truncate silently.
- Error Handling: Redaction rules should mask anything resembling API keys in both directions; implement a small utility used by all error surfaces.
- Performance: Web export is static; Electron ships the same bundle — simple. Watch bundle size (CodeMirror + Tamagui). Consider code splitting for prompt editor on demand.
- Testing: Plans include unit/component/integration; add a couple of golden-path manual scripts (LLM disabled, create doc fail, offline search) for quick smoke checks.
- API Model: Single table and vector index are minimal — good. Add a defensive check that embedding returns a vector of expected length; otherwise fail with 500 and provider text.
- Pagination: Omitted deliberately. Keep list at 50; avoid infinite scroll until needed.
- Consistency: Partial failure between Vectorize and D1 left unresolved — acceptable for v1; capture correlationId and log both writes to ease cleanup.

## Operational
- Environments/Branches: develop→staging, main→production is clear. Good foundation for push-based deploys.
- CI/CD: Workflows described; add guardrails: require checks passing before deploy job runs; protect main with required reviews.
- Migrations: schema.sql applied in prod when needed; prefer applying to staging first automatically, then promote.
- Backups: Nightly D1 export proposed; specify retention (7–30 days) and a basic restore runbook (already hinted).
- Observability: Structured logs + wrangler tail; optional Sentry. Add a minimal correlationId middleware in the Worker and include it in all logs/responses.
- CORS: Lock to staging/prod origins in their respective envs; keep dev permissive.
- Rate Limiting: Basic CF Firewall rate rules OK; document initial thresholds (e.g., 60 rpm per IP on write endpoints).
- Secrets: CI/CF managed; reiterate no secrets in client bundles. Ensure error redaction in Worker before returning to client.
- Rollbacks: Pages/Workers rollback covered. For D1, emphasize that schema changes are additive in v1; avoid destructive changes.
- Onboarding: Clear steps defined; add a “first success” checklist (open dev server, create a document, run a search) to validate environment quickly.

## Specific Gotchas & Rough Patches
- OpenRouter Models API dependency: If it changes or rate-limits, model list will fail; caching helps. Consider minimal hand-curated fallback list with a warning in case both live and cache are empty.
- Streaming Chat: Provider/model inconsistencies for streaming can cause UX variance. Implement a simple adapter that falls back to buffered if streaming events aren’t reliable.
- Electron Security: Packaging a web export is fine; ensure `contextIsolation` and disable `nodeIntegration` in Electron to reduce risk.
- Vector Metadata: Only `title` stored. If titles are non-unique, search results may confuse. Consider adding `created` timestamp to metadata for better tie-breaking (not required to ship v1).
- Content Size: 32k char limit may still be large for embeddings cost/latency. Track average times; consider warning users above 8–16k.
- Error Noise: Surfacing raw provider errors can be noisy/cryptic. Keep the raw text, but add a short, consistent human-readable summary above it.

## Opportunities to Improve (Low Effort, High Value)
- Add a tiny “Health” endpoint `/api/health` returning static JSON with timestamp and bindings presence for monitoring/CI smoke tests.
- Add a shared error schema in the API (`{ error, status, timestamp, correlationId }`) and a client parser to standardize UI.
- Add last-updated timestamps for cached items (model list, document list) to increase trust.
- Add a simple feature flag mechanism (env-driven) for streaming, snippets, and proxying LLM calls later.
- Provide a “Copy error details” action in error toasts/blocks to aid support without exposing secrets.

## Proposed Adjustments (Respecting Simplicity First)
- Defer snippets, proxies, pagination, and complex retries; keep the current minimal product.
- Implement: correlationId middleware, standard error payload shape, client redaction utility, token-length warning, and health endpoint.
- Lock CORS per env and add minimal rate limits on POST `/api/documents`.
- Load prompt editor code on demand to keep initial bundle lean.

## Open Questions
- Should we persist chat history locally per device (no server), or keep strictly ephemeral? Current spec says ephemeral; confirm desired behavior.
- What’s the acceptable maximum content length from a product/latency perspective (8k vs 16k vs 32k)?
- Are there compliance constraints (data residency/PII) for document content that warrant regional pinning or additional disclaimers?

## Next Steps
- Add small amendments to specs: error schema, correlationId, token-length warnings, CORS tightening, health endpoint.
- Optionally add example GitHub Actions workflows and env-specific Wrangler configs to operationalize the plan.

